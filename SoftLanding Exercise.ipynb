{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65fb0b19",
   "metadata": {},
   "source": [
    "# Soft Landing with an Aerial Manipulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ebb919",
   "metadata": {},
   "source": [
    "In this exercise your task is to make an Aerial Manipulator land as softly, and doing so as energy efficient as possible. The tricky part: you have no information about your height!\n",
    "\n",
    "## OpenAIs Gymnasium (aka Gym)\n",
    "\n",
    "The environment is adapted from the example [\"Bipedal Walker\"](https://www.gymlibrary.dev/environments/box2d/bipedal_walker/) from the standard examples of the OpenAI Gym environments. \n",
    "The environments work based on the standard systems approach: you input some action and the system outputs the resulting observations.\n",
    "\n",
    "## Action Space\n",
    "\n",
    "The Aerial Manipulator (AM) is a 2D Bi-Rotor with two articulated arms, each with two revolute joints. The action space consists of the input into each of these motors in the following order:\n",
    "\n",
    "- Rotor 1\n",
    "- Rotor 2\n",
    "- Arm 1, Joint 1  \n",
    "- Arm 1, Joint 2 \n",
    "- Arm 2, Joint 1  \n",
    "- Arm 2 Joint 2\n",
    "\n",
    "## Observation Space\n",
    "\n",
    "The observation space consist of measurements that are commonly available via proprioceptive sensors on an AM: angular positions and speeds, linear velocities, as well as contact information. The order is as following:\n",
    "- Base Angular Position\n",
    "- Base Linear Velocity (x)\n",
    "- Base Linear Velocity (y)\n",
    "- Arm 1, Joint 1 Position\n",
    "- Arm 1, Joint 1 Speed\n",
    "- Arm 1, Joint 2 Position\n",
    "- Arm 1, Joint 2 Speed,\n",
    "- Arm 1, EE in contact (Binary)\n",
    "- Arm 2, Joint 1 Position\n",
    "- Arm 2, Joint 1 Speed\n",
    "- Arm 2, Joint 2 Position\n",
    "- Arm 2, Joint 2 Speed,\n",
    "- Arm 2, EE in contact (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ce8828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we import the needed libraries and setup the environment\n",
    "# You don't need to touch this\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from dual_arm_am import DualArmAM\n",
    "\n",
    "env = DualArmAM(render_mode='human')\n",
    "env._max_episode_steps = 600\n",
    "env.reset()\n",
    "steps = 0\n",
    "total_reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bb25737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where you do your work. By changing the action (a) you can command the AM\n",
    "\n",
    "def control_law(s):\n",
    "    ###################### Simple Heuristic: ###########################\n",
    "    ####### The quadrotor slowly descends while constant torque   ######\n",
    "    ####### on the joint motors                                   ######\n",
    "    ####################################################################\n",
    "    \n",
    "    theta = s[0]\n",
    "    thetadot = s[1]\n",
    "    xdot = s[2]\n",
    "    ydot = s[3]\n",
    "    j0 = s[4]\n",
    "    j0dot = s[5]\n",
    "    j1 = s[6]\n",
    "    j1dot = s[7]\n",
    "    j2 = s[9]\n",
    "    j2dot = s[10]\n",
    "    j3 = s[11]\n",
    "    j3dot = s[12]\n",
    "\n",
    "    # First the descending control of the quadrotor:\n",
    "    # Simple PD control on attitude while maintaining thrust\n",
    "    # That is a bit less then the gravity\n",
    "    k_att = 1\n",
    "    d_att = 0.1\n",
    "    a[0] = -k_att *theta + d_att * thetadot\n",
    "    a[1] = (k_att *theta + d_att * thetadot)\n",
    "\n",
    "    # Add thrust to have total thrust that (almost) matches gravity\n",
    "    addon = np.cos(theta) * 0.50\n",
    "    a[0] += addon\n",
    "    a[1] += addon\n",
    "\n",
    "    a[2] = 2.0\n",
    "    a[3] = 0.005\n",
    "    a[4] = -2.0\n",
    "    a[5] = -0.005\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f455f0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3967/2973579104.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_law\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/am-gym-env/dual_arm_am.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"human\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/am-gym-env/dual_arm_am.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"human\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscroll\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mSCALE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"render_fps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "# This runs one episode of the environment and outputs the cumulative reward\n",
    "\n",
    "s =  np.zeros(env.observation_space.shape)\n",
    "while True:\n",
    "        s, r, terminated, truncated, info = env.step(control_law(s))\n",
    "        total_reward += r\n",
    "        if steps % 20 == 0 or terminated or truncated:\n",
    "            print(\"\\naction \" + str([f\"{x:+0.2f}\" for x in a]))\n",
    "            print(f\"step {steps} total_reward {total_reward:+0.2f}\")\n",
    "            print(\"hull \" + str([f\"{x:+0.2f}\" for x in s[0:4]]))\n",
    "            print(\"leg0 \" + str([f\"{x:+0.2f}\" for x in s[4:9]]))\n",
    "            print(\"leg1 \" + str([f\"{x:+0.2f}\" for x in s[9:14]]))\n",
    "        steps += 1\n",
    "\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "            \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e961ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
